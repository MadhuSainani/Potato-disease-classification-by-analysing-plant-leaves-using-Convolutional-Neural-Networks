# -*- coding: utf-8 -*-
"""Comparison_with_pre-trained_models.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1B20zlyA0FF-5Pi10CQWX4Xe-SRybG-Wq
"""

from google.colab import drive
drive.mount('/content/drive')

import zipfile
import os

#importing dataset
dataset_directory = os.listdir('/content/drive/MyDrive/Plant_Village_data/PotatoLeafImage_data')
for filenames in dataset_directory:
    print(filenames)

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import tensorflow as tf
from tensorflow import keras
import cv2

#Global initialization of some imp variables
Image_Size = 224
Batch_Size = 16
Channels = 3

dataset_directory = '/content/drive/MyDrive/Plant_Village_data/PotatoLeafImage_data'
dataset = tf.keras.preprocessing.image_dataset_from_directory(
    dataset_directory,  # this should be a string, not a list
    batch_size=Batch_Size,
    image_size=(Image_Size, Image_Size),
    shuffle=True
)

#Folders(classes) in 'Dataset' directory
class_name = dataset.class_names
class_name

len(dataset) # Number of Batches = (total number of files belonging to all classes / Batch_Size)

def split_dataset(ds, train_split=0.8, val_split=0.1, test_split=0.1, shuffle=True, shuffle_size=10000):

    if shuffle:
        ds = ds.shuffle(shuffle_size, seed = 10)

    ds_size = len(ds)
    train_size = int(train_split * ds_size)
    val_size = int(val_split * ds_size)

    train_ds = ds.take(train_size)
    val_ds = ds.skip(train_size).take(val_size)
    test_ds = ds.skip(train_size + val_size)

    return train_ds, val_ds, test_ds

train_data, val_data, test_data = split_dataset(dataset)

print("Size of Data is :{0} \nBatch size of Training Data is :{1}\nBatch size of Validation Data is :{2} \nBatch size of Testing Data is :{3} " .format(len(dataset), len(train_data), len(val_data), len(test_data)))

from tensorflow.keras.applications import InceptionV3
from tensorflow.keras import layers
from tensorflow.keras import Model

# Image Preprocessing : Rescaling and Resizing
resize_and_rescale = tf.keras.Sequential([
    layers.experimental.preprocessing.Resizing(Image_Size, Image_Size),
    layers.experimental.preprocessing.Rescaling(1.0/255)
])

# Define the data augmentation in a Sequential model
data_augmentation = tf.keras.Sequential([
  layers.experimental.preprocessing.RandomFlip("horizontal_and_vertical"),
  layers.experimental.preprocessing.RandomRotation(0.2),
  layers.experimental.preprocessing.RandomZoom(0.2),
  layers.experimental.preprocessing.RandomTranslation(height_factor=0.2, width_factor=0.2, fill_mode='nearest'),
  layers.experimental.preprocessing.RandomContrast(factor=0.2)
])

train_ds = train_data.cache().shuffle(1000).map(
  lambda x, y: (data_augmentation(x, training=True), y)
).prefetch(buffer_size=tf.data.AUTOTUNE)
val_ds = val_data.cache().prefetch(buffer_size=tf.data.AUTOTUNE)
test_ds = test_data.cache().prefetch(buffer_size=tf.data.AUTOTUNE)

input_shape = (Batch_Size, Image_Size, Image_Size, Channels)

base_model = tf.keras.applications.InceptionV3(input_shape=(Image_Size, Image_Size, Channels),
                                               include_top=False,
                                               weights='imagenet')

# Freezing the base model
base_model.trainable = False

# Creating the InceptionV3 model
mdL_inceptionv3 = tf.keras.Sequential([
    resize_and_rescale,
    base_model,
    layers.GlobalAveragePooling2D(),
    layers.Dense(3, activation='softmax')
])
mdL_inceptionv3.build(input_shape = input_shape)
mdL_inceptionv3.summary()

mdL_inceptionv3.compile(
    optimizer = 'adam',
    loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits = False),
    metrics = ['accuracy'])

#Fit the model with training data and also pass validation data
history1_inceptionv3 = mdL_inceptionv3.fit(
train_ds, epochs = 200, batch_size = Batch_Size, verbose = 1, validation_data = val_ds)

# Getting the model history to analyse
train_loss = history1_inceptionv3.history['loss']
train_acc = history1_inceptionv3.history['accuracy']

val_loss = history1_inceptionv3.history['val_loss']
val_acc = history1_inceptionv3.history['val_accuracy']

plt.figure(figsize=(12, 7))
plt.subplot(1, 2, 1)
plt.plot(range(len(train_acc)), train_acc, label='Training Accuracy')
plt.plot(range(len(val_acc)), val_acc, label='Validation Accuracy')
plt.legend(loc='lower right')
plt.title('Training and Validation Accuracy')

plt.subplot(1, 2, 2)
plt.plot(range(len(train_loss)), train_loss, label='Training Loss')
plt.plot(range(len(val_loss)), val_loss, label='Validation Loss')
plt.legend(loc='upper right')
plt.title('Training and Validation Loss')

mdL_inceptionv3.save('/content/drive/My Drive/mdL_inceptionv3')

model_path = '/content/drive/My Drive/mdL_inceptionv3'
Model_InceptionV3 = tf.keras.models.load_model(model_path)

scores = Model_InceptionV3.evaluate(test_ds)

predictions = Model_InceptionV3.predict(test_ds)
predicted_labels = np.argmax(predictions, axis=-1)
true_labels = []
for _, y in test_ds:
    true_labels.extend(y.numpy())

# Convert list to numpy array
true_labels = np.array(true_labels)

from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, roc_auc_score

# Classification report for precision, recall, f1-score
report = classification_report(true_labels, predicted_labels, target_names=['Potato Early Blight', 'Potato Late Blight', 'Potato Healthy'])
print(report)

# Confusion Matrix
conf_matrix = confusion_matrix(true_labels, predicted_labels)
print(conf_matrix)

# Accuracy
accuracy = accuracy_score(true_labels, predicted_labels)
print(f'Accuracy: {accuracy}')

from sklearn.preprocessing import label_binarize
from sklearn.metrics import roc_auc_score

# Binarize the true labels
y_binarized = label_binarize(true_labels, classes=[0, 1, 2])

# Calculate AUC-ROC
# The "ovr" means "one versus rest"
roc_auc = roc_auc_score(y_binarized, predictions, multi_class='ovr')
print(f'AUC-ROC: {roc_auc}')

from sklearn.metrics import roc_curve
import matplotlib.pyplot as plt

# Compute ROC curve for each class
fpr = dict()
tpr = dict()
roc_auc = dict()
n_classes = 3

for i in range(n_classes):
    fpr[i], tpr[i], _ = roc_curve(y_binarized[:, i], predictions[:, i])
    roc_auc[i] = roc_auc_score(y_binarized[:, i], predictions[:, i])

# Plotting
for i in range(n_classes):
    plt.figure()
    plt.plot(fpr[i], tpr[i], label='ROC curve (area = %0.2f)' % roc_auc[i])
    plt.plot([0, 1], [0, 1], 'k--')
    plt.xlim([0.0, 1.0])
    plt.ylim([0.0, 1.05])
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.title('Receiver Operating Characteristic for class {}'.format(i))
    plt.legend(loc="lower right")
    plt.show()

input_shape = (Batch_Size, Image_Size, Image_Size, Channels)

base_model = tf.keras.applications.MobileNetV2(input_shape=(Image_Size, Image_Size, Channels),
                                               include_top=False,
                                               weights='imagenet')

# Freezing the base model
base_model.trainable = False

# Creating the MobileNetV2 model
mdL_Mobilenetv2 = tf.keras.Sequential([
    resize_and_rescale,
    base_model,
    layers.GlobalAveragePooling2D(),
    layers.Dense(3, activation='softmax')
])
mdL_Mobilenetv2.build(input_shape = input_shape)
mdL_Mobilenetv2.summary()

mdL_Mobilenetv2.compile(
    optimizer = 'adam',
    loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits = False),
    metrics = ['accuracy'])

#Fit the model with training data and also pass validation data
history1_mobilenetv2 = mdL_Mobilenetv2.fit(
train_ds, epochs = 200, batch_size = Batch_Size, verbose = 1, validation_data = val_ds)

# Getting the model history to analyse
train_loss = history1_mobilenetv2.history['loss']
train_acc = history1_mobilenetv2.history['accuracy']

val_loss = history1_mobilenetv2.history['val_loss']
val_acc = history1_mobilenetv2.history['val_accuracy']

plt.figure(figsize=(12, 7))
plt.subplot(1, 2, 1)
plt.plot(range(len(train_acc)), train_acc, label='Training Accuracy')
plt.plot(range(len(val_acc)), val_acc, label='Validation Accuracy')
plt.legend(loc='lower right')
plt.title('Training and Validation Accuracy')

plt.subplot(1, 2, 2)
plt.plot(range(len(train_loss)), train_loss, label='Training Loss')
plt.plot(range(len(val_loss)), val_loss, label='Validation Loss')
plt.legend(loc='upper right')
plt.title('Training and Validation Loss')

mdL_Mobilenetv2.save('/content/drive/My Drive/mdL_Mobilenetv2')

model_path = '/content/drive/My Drive/mdL_Mobilenetv2'
Model_MobilNetV2 = tf.keras.models.load_model(model_path)

scores = Model_MobilNetV2.evaluate(test_ds)

predictions = Model_MobilNetV2.predict(test_ds)
predicted_labels = np.argmax(predictions, axis=-1)
true_labels = []
for _, y in test_ds:
    true_labels.extend(y.numpy())

# Convert list to numpy array
true_labels = np.array(true_labels)

from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, roc_auc_score

# Classification report for precision, recall, f1-score
report = classification_report(true_labels, predicted_labels, target_names=['Potato Early Blight', 'Potato Late Blight', 'Potato Healthy'])
print(report)

# Confusion Matrix
conf_matrix = confusion_matrix(true_labels, predicted_labels)
print(conf_matrix)

# Accuracy
accuracy = accuracy_score(true_labels, predicted_labels)
print(f'Accuracy: {accuracy}')

from sklearn.preprocessing import label_binarize
from sklearn.metrics import roc_auc_score

# Binarize the true labels
y_binarized = label_binarize(true_labels, classes=[0, 1, 2])

# Calculate AUC-ROC
# The "ovr" means "one versus rest"
roc_auc = roc_auc_score(y_binarized, predictions, multi_class='ovr')
print(f'AUC-ROC: {roc_auc}')

from sklearn.metrics import roc_curve
import matplotlib.pyplot as plt

# Compute ROC curve for each class
fpr = dict()
tpr = dict()
roc_auc = dict()
n_classes = 3

for i in range(n_classes):
    fpr[i], tpr[i], _ = roc_curve(y_binarized[:, i], predictions[:, i])
    roc_auc[i] = roc_auc_score(y_binarized[:, i], predictions[:, i])

# Plotting
for i in range(n_classes):
    plt.figure()
    plt.plot(fpr[i], tpr[i], label='ROC curve (area = %0.2f)' % roc_auc[i])
    plt.plot([0, 1], [0, 1], 'k--')
    plt.xlim([0.0, 1.0])
    plt.ylim([0.0, 1.05])
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.title('Receiver Operating Characteristic for class {}'.format(i))
    plt.legend(loc="lower right")
    plt.show()

# MobileNet Pre-trained Model
input_shape = (Batch_Size, Image_Size, Image_Size, Channels)

base_model = tf.keras.applications.MobileNet(input_shape=(Image_Size, Image_Size, Channels),
                                               include_top=False,
                                               weights='imagenet')

# Freezing the base model
base_model.trainable = False

# Creating the MobileNet model
mdL_mobilenet = tf.keras.Sequential([
    resize_and_rescale,
    base_model,
    layers.GlobalAveragePooling2D(),
    layers.Dense(3, activation='softmax')
])
mdL_mobilenet.build(input_shape = input_shape)
mdL_mobilenet.summary()

mdL_mobilenet.compile(
    optimizer = 'adam',
    loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits = False),
    metrics = ['accuracy'])

#Fit the model with training data and also pass validation data
history1_mobilenet = mdL_mobilenet.fit(
train_ds, epochs = 200, batch_size = Batch_Size, verbose = 1, validation_data = val_ds)

# Getting the model history to analyse
train_loss = history1_mobilenet.history['loss']
train_acc = history1_mobilenet.history['accuracy']

val_loss = history1_mobilenet.history['val_loss']
val_acc = history1_mobilenet.history['val_accuracy']

plt.figure(figsize=(12, 7))
plt.subplot(1, 2, 1)
plt.plot(range(len(train_acc)), train_acc, label='Training Accuracy')
plt.plot(range(len(val_acc)), val_acc, label='Validation Accuracy')
plt.legend(loc='lower right')
plt.title('Training and Validation Accuracy')

plt.subplot(1, 2, 2)
plt.plot(range(len(train_loss)), train_loss, label='Training Loss')
plt.plot(range(len(val_loss)), val_loss, label='Validation Loss')
plt.legend(loc='upper right')
plt.title('Training and Validation Loss')

mdL_mobilenet.save('/content/drive/My Drive/mdL_Mobilenet')

model_path = '/content/drive/My Drive/mdL_Mobilenet'
Model_MobilNet = tf.keras.models.load_model(model_path)

scores = Model_MobilNet.evaluate(test_ds)

predictions = Model_MobilNet.predict(test_ds)
predicted_labels = np.argmax(predictions, axis=-1)
true_labels = []
for _, y in test_ds:
    true_labels.extend(y.numpy())

# Convert list to numpy array
true_labels = np.array(true_labels)

from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, roc_auc_score

# Classification report for precision, recall, f1-score
report = classification_report(true_labels, predicted_labels, target_names=['Potato Early Blight', 'Potato Late Blight', 'Potato Healthy'])
print(report)

# Confusion Matrix
conf_matrix = confusion_matrix(true_labels, predicted_labels)
print(conf_matrix)

# Accuracy
accuracy = accuracy_score(true_labels, predicted_labels)
print(f'Accuracy: {accuracy}')

from sklearn.preprocessing import label_binarize
from sklearn.metrics import roc_auc_score

# Binarize the true labels
y_binarized = label_binarize(true_labels, classes=[0, 1, 2])

# Calculate AUC-ROC
# The "ovr" means "one versus rest"
roc_auc = roc_auc_score(y_binarized, predictions, multi_class='ovr')
print(f'AUC-ROC: {roc_auc}')

# ResNet50 Pre-trained Model
input_shape = (Batch_Size, Image_Size, Image_Size, Channels)

base_model = tf.keras.applications.ResNet50(input_shape=(Image_Size, Image_Size, Channels),
                                               include_top=False,
                                               weights='imagenet')

# Freezing the base model
base_model.trainable = False

# Creating the ResNet50 model
mdL_resnet50 = tf.keras.Sequential([
    resize_and_rescale,
    base_model,
    layers.GlobalAveragePooling2D(),
    layers.Dense(3, activation='softmax')
])
mdL_resnet50.build(input_shape = input_shape)
mdL_resnet50.summary()

mdL_resnet50.compile(
    optimizer = 'adam',
    loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits = False),
    metrics = ['accuracy'])

#Fit the model with training data and also pass validation data
history1_resnet50 = mdL_resnet50.fit(
train_ds, epochs = 200, batch_size = Batch_Size, verbose = 1, validation_data = val_ds)

mdL_resnet50.save('/content/drive/My Drive/mdL_resnet')

model_path = '/content/drive/My Drive/mdL_resnet'
Model_ResNet50 = tf.keras.models.load_model(model_path)

scores = Model_ResNet50.evaluate(test_ds)

# Getting the model history to analyse
train_loss = history1_resnet50.history['loss']
train_acc = history1_resnet50.history['accuracy']

val_loss = history1_resnet50.history['val_loss']
val_acc = history1_resnet50.history['val_accuracy']

plt.figure(figsize=(12, 7))
plt.subplot(1, 2, 1)
plt.plot(range(len(train_acc)), train_acc, label='Training Accuracy')
plt.plot(range(len(val_acc)), val_acc, label='Validation Accuracy')
plt.legend(loc='lower right')
plt.title('Training and Validation Accuracy')

plt.subplot(1, 2, 2)
plt.plot(range(len(train_loss)), train_loss, label='Training Loss')
plt.plot(range(len(val_loss)), val_loss, label='Validation Loss')
plt.legend(loc='upper right')
plt.title('Training and Validation Loss')

predictions = Model_ResNet50.predict(test_ds)
predicted_labels = np.argmax(predictions, axis=-1)
true_labels = []
for _, y in test_ds:
    true_labels.extend(y.numpy())

# Convert list to numpy array
true_labels = np.array(true_labels)

from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, roc_auc_score

# Classification report for precision, recall, f1-score
report = classification_report(true_labels, predicted_labels, target_names=['Potato Early Blight', 'Potato Late Blight', 'Potato Healthy'])
print(report)

# Confusion Matrix
conf_matrix = confusion_matrix(true_labels, predicted_labels)
print(conf_matrix)

# Accuracy
accuracy = accuracy_score(true_labels, predicted_labels)
print(f'Accuracy: {accuracy}')

from sklearn.preprocessing import label_binarize
from sklearn.metrics import roc_auc_score

# Binarize the true labels
y_binarized = label_binarize(true_labels, classes=[0, 1, 2])

# Calculate AUC-ROC
# The "ovr" means "one versus rest"
roc_auc = roc_auc_score(y_binarized, predictions, multi_class='ovr')
print(f'AUC-ROC: {roc_auc}')