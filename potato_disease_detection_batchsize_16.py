# -*- coding: utf-8 -*-
"""Potato_Disease_Detection_BatchSize_16.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1_-idLUkjmId6xM73nuqYamOa1j5eJx7g
"""

from google.colab import drive
drive.mount('/content/drive')

import zipfile
import os

#importing dataset
dataset_directory = os.listdir('/content/drive/MyDrive/Plant_Village_data/PotatoLeafImage_data')
for filenames in dataset_directory:
    print(filenames)

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import tensorflow as tf
from tensorflow import keras
import cv2

#Global initialization of some imp variables
Image_Size = 256
Batch_Size = 16
Channels = 3

dataset_directory = '/content/drive/MyDrive/Plant_Village_data/PotatoLeafImage_data'
dataset = tf.keras.preprocessing.image_dataset_from_directory(
    dataset_directory,  # this should be a string, not a list
    batch_size=Batch_Size,
    image_size=(Image_Size, Image_Size),
    shuffle=True
)

#Folders(classes) in 'Dataset' directory
class_name = dataset.class_names
class_name

len(dataset) # Number of Batches = (total number of files belonging to all classes / Batch_Size)

def split_dataset(ds, train_split=0.8, val_split=0.1, test_split=0.1, shuffle=True, shuffle_size=10000):

    if shuffle:
        ds = ds.shuffle(shuffle_size, seed = 10)

    ds_size = len(ds)
    train_size = int(train_split * ds_size)
    val_size = int(val_split * ds_size)

    train_ds = ds.take(train_size)
    val_ds = ds.skip(train_size).take(val_size)
    test_ds = ds.skip(train_size + val_size)

    return train_ds, val_ds, test_ds

train_data, val_data, test_data = split_dataset(dataset)

print("Size of Data is :{0} \nBatch size of Training Data is :{1}\nBatch size of Validation Data is :{2} \nBatch size of Testing Data is :{3} " .format(len(dataset), len(train_data), len(val_data), len(test_data)))

import tensorflow as tf
from tensorflow.keras import layers

# Image Preprocessing : Rescaling and Resizing
resize_and_rescale = tf.keras.Sequential([
    layers.experimental.preprocessing.Resizing(Image_Size, Image_Size),
    layers.experimental.preprocessing.Rescaling(1.0/255)
])

# Define the data augmentation in a Sequential model
data_augmentation = tf.keras.Sequential([
  layers.experimental.preprocessing.RandomFlip("horizontal_and_vertical"),
  layers.experimental.preprocessing.RandomRotation(0.2),
  layers.experimental.preprocessing.RandomZoom(0.2),
  layers.experimental.preprocessing.RandomTranslation(height_factor=0.2, width_factor=0.2, fill_mode='nearest'),
  layers.experimental.preprocessing.RandomContrast(factor=0.2)
])

train_ds = train_data.cache().shuffle(1000).map(
  lambda x, y: (data_augmentation(x, training=True), y)
).prefetch(buffer_size=tf.data.AUTOTUNE)
val_ds = val_data.cache().prefetch(buffer_size=tf.data.AUTOTUNE)
test_ds = test_data.cache().prefetch(buffer_size=tf.data.AUTOTUNE)

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Activation
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.losses import CategoricalCrossentropy

# Model at Batch Size 16 and Learning Rate 0.0001
input_shape = (Batch_Size, Image_Size, Image_Size, Channels)
model16_DR4_0001 = Sequential([
    resize_and_rescale,
    layers.Conv2D(filters=16, kernel_size=(3,3), activation='relu', input_shape=input_shape),
    layers.MaxPool2D((2,2)),

    layers.Conv2D(32, (3,3), activation='relu'),
    layers.MaxPool2D((2,2)),

    layers.Conv2D(64, (3,3), activation='relu'),
    layers.MaxPool2D((2,2)),
    layers.GlobalAveragePooling2D(),
    layers.Dense(64, activation='relu'),
    layers.Dropout(0.4),
    layers.Dense(3, activation='softmax')
])
model16_DR4_0001.build(input_shape = input_shape)
model16_DR4_0001.summary()

learning_rate = 0.0001
adam_optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)
model16_DR4_0001.compile(
    optimizer=adam_optimizer,
    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),
    metrics=['accuracy'])

#Fit the model with training data and also pass validation data
history16_DR4_0001 = model16_DR4_0001.fit(
train_ds, epochs = 200, batch_size = Batch_Size, verbose = 1, validation_data = val_ds)

# Getting the model history to analyse
train_loss = history16_DR4_0001.history['loss']
train_acc = history16_DR4_0001.history['accuracy']

val_loss = history16_DR4_0001.history['val_loss']
val_acc = history16_DR4_0001.history['val_accuracy']

plt.figure(figsize=(12, 7))
plt.subplot(1, 2, 1)
plt.plot(range(len(train_acc)), train_acc, label='Training Accuracy')
plt.plot(range(len(val_acc)), val_acc, label='Validation Accuracy')
plt.legend(loc='lower right')
plt.title('Training and Validation Accuracy')

plt.subplot(1, 2, 2)
plt.plot(range(len(train_loss)), train_loss, label='Training Loss')
plt.plot(range(len(val_loss)), val_loss, label='Validation Loss')
plt.legend(loc='upper right')
plt.title('Training and Validation Loss')

# Model at Batch Size 16 and Learning Rate 0.001
input_shape = (Batch_Size, Image_Size, Image_Size, Channels)
model_16_DR4_001 = Sequential([
    resize_and_rescale,
    layers.Conv2D(filters=16, kernel_size=(3,3), activation='relu', input_shape=input_shape),
    layers.MaxPool2D((2,2)),

    layers.Conv2D(32, (3,3), activation='relu'),
    layers.MaxPool2D((2,2)),

    layers.Conv2D(64, (3,3), activation='relu'),
    layers.MaxPool2D((2,2)),
    layers.GlobalAveragePooling2D(),
    layers.Dense(64, activation='relu'),
    layers.Dropout(0.4),
    layers.Dense(3, activation='softmax')
])
model_16_DR4_001.build(input_shape = input_shape)
model_16_DR4_001.summary()

learning_rate = 0.001
adam_optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)
model_16_DR4_001.compile(
    optimizer=adam_optimizer,
    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),
    metrics=['accuracy'])

#Fit the model with training data and also pass validation data
history_16_DR4_001 = model_16_DR4_001.fit(
train_ds, epochs = 200, batch_size = Batch_Size, verbose = 1, validation_data = val_ds)

model_path = '/content/drive/My Drive/best_model_16_DR4_001'
loaded_model = tf.keras.models.load_model(model_path)

scores = loaded_model.evaluate(test_ds)

predictions = loaded_model.predict(test_ds)
predictions

import numpy as np
predicted_labels = np.argmax(predictions, axis=-1)
# Assuming that each element in test_ds is a (data, label) tuple
true_labels = []
for _, y in test_ds:
    true_labels.extend(y.numpy())

# Convert list to numpy array
true_labels = np.array(true_labels)

print("Length of true_labels:", len(true_labels))
print("Length of predicted_labels:", len(predicted_labels))

from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, roc_auc_score

# Classification report for precision, recall, f1-score
report = classification_report(true_labels, predicted_labels, target_names=['Potato Healthy', 'Potato Early Blight', 'Potato Late Blight'])
print(report)

# Confusion Matrix
conf_matrix = confusion_matrix(true_labels, predicted_labels)
print(conf_matrix)

# Accuracy
accuracy = accuracy_score(true_labels, predicted_labels)
print(f'Accuracy: {accuracy}')

from sklearn.preprocessing import label_binarize
from sklearn.metrics import roc_auc_score

# Binarize the true labels
y_binarized = label_binarize(true_labels, classes=[0, 1, 2])

# Calculate AUC-ROC
roc_auc = roc_auc_score(y_binarized, predictions, multi_class='ovr')
print(f'AUC-ROC: {roc_auc}')

from sklearn.metrics import roc_curve
import matplotlib.pyplot as plt

# Compute ROC curve for each class
fpr = dict()
tpr = dict()
roc_auc = dict()
n_classes = 3

for i in range(n_classes):
    fpr[i], tpr[i], _ = roc_curve(y_binarized[:, i], predictions[:, i])
    roc_auc[i] = roc_auc_score(y_binarized[:, i], predictions[:, i])

# Plotting
for i in range(n_classes):
    plt.figure()
    plt.plot(fpr[i], tpr[i], label='ROC curve (area = %0.2f)' % roc_auc[i])
    plt.plot([0, 1], [0, 1], 'k--')
    plt.xlim([0.0, 1.0])
    plt.ylim([0.0, 1.05])
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.title('Receiver Operating Characteristic for class {}'.format(i))
    plt.legend(loc="lower right")
    plt.show()

# Getting the model history to analyse
train_loss = history_16_DR4_001.history['loss']
train_acc = history_16_DR4_001.history['accuracy']

val_loss = history_16_DR4_001.history['val_loss']
val_acc = history_16_DR4_001.history['val_accuracy']

plt.figure(figsize=(12, 7))
plt.subplot(1, 2, 1)
plt.plot(range(len(train_acc)), train_acc, label='Training Accuracy')
plt.plot(range(len(val_acc)), val_acc, label='Validation Accuracy')
plt.legend(loc='lower right')
plt.title('Training and Validation Accuracy')

plt.subplot(1, 2, 2)
plt.plot(range(len(train_loss)), train_loss, label='Training Loss')
plt.plot(range(len(val_loss)), val_loss, label='Validation Loss')
plt.legend(loc='upper right')
plt.title('Training and Validation Loss')

model_16_DR4_001.save('/content/drive/My Drive/best_model_16_DR4_001')

# Model at Batch Size 16 and Learning Rate 0.01
input_shape = (Batch_Size, Image_Size, Image_Size, Channels)
model16_DR4_01 = Sequential([
    resize_and_rescale,
    layers.Conv2D(filters=16, kernel_size=(3,3), activation='relu', input_shape=input_shape),
    layers.MaxPool2D((2,2)),

    layers.Conv2D(32, (3,3), activation='relu'),
    layers.MaxPool2D((2,2)),

    layers.Conv2D(64, (3,3), activation='relu'),
    layers.MaxPool2D((2,2)),
    layers.GlobalAveragePooling2D(),
    layers.Dense(64, activation='relu'),
    layers.Dropout(0.4),
    layers.Dense(3, activation='softmax')
])
model16_DR4_01.build(input_shape = input_shape)
model16_DR4_01.summary()

learning_rate = 0.01
adam_optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)
model16_DR4_01.compile(
    optimizer=adam_optimizer,
    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),
    metrics=['accuracy'])

#Fit the model with training data and also pass validation data
history16_DR4_01 = model16_DR4_01.fit(
train_ds, epochs = 200, batch_size = Batch_Size, verbose = 1, validation_data = val_ds)

# Getting the model history to analyse
train_loss = history16_DR4_01.history['loss']
train_acc = history16_DR4_01.history['accuracy']

val_loss = history16_DR4_01.history['val_loss']
val_acc = history16_DR4_01.history['val_accuracy']

plt.figure(figsize=(12, 7))
plt.subplot(1, 2, 1)
plt.plot(range(len(train_acc)), train_acc, label='Training Accuracy')
plt.plot(range(len(val_acc)), val_acc, label='Validation Accuracy')
plt.legend(loc='lower right')
plt.title('Training and Validation Accuracy')

plt.subplot(1, 2, 2)
plt.plot(range(len(train_loss)), train_loss, label='Training Loss')
plt.plot(range(len(val_loss)), val_loss, label='Validation Loss')
plt.legend(loc='upper right')
plt.title('Training and Validation Loss')